{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882bd8f4-ffdd-4f3f-98db-b62138fd9389",
   "metadata": {},
   "source": [
    "# Using Bedrock , Evaluating the Ideal Chunk Size for a RAG System using LlamaIndex\n",
    "\n",
    "- https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5\n",
    "- Colab\n",
    "    - https://colab.research.google.com/drive/1LPvJyEON6btMpubYdwySfNs0FuNR9nza?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c920cb64-62a9-41f2-8032-83072b5d102f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/02_qa_chatbot/01_preprocess_docs/utils\n",
      "/root/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/02_qa_chatbot/01_preprocess_docs\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "# module_path = \"../../../utils\"\n",
    "# sys.path.append(os.path.abspath(module_path))\n",
    "# print(os.path.abspath(module_path))\n",
    "\n",
    "\n",
    "module_path = \"../utils\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "print(os.path.abspath(module_path))\n",
    "\n",
    "module_path = \"../\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "print(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e960ad81-ebe5-44f2-b058-cb43e6b7b5ee",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea8c30f-eb9c-4082-955f-b966bba56100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install llama-index pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed8be2b-692a-4735-abdc-7a141b7c292e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    ")\n",
    "from llama_index.evaluation import (\n",
    "    DatasetGenerator,\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator\n",
    ")\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450ea34-7f1c-4122-9ce0-9b03cd2ae3fa",
   "metadata": {},
   "source": [
    "# 2. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37b9558c-5a62-45c9-9bc2-6ba2af94fe8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-18 11:36:22--  https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/examples/data/10k/uber_2021.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1880483 (1.8M) [application/octet-stream]\n",
      "Saving to: ‘data/10k/uber_2021.pdf’\n",
      "\n",
      "data/10k/uber_2021. 100%[===================>]   1.79M  --.-KB/s    in 0.01s   \n",
      "\n",
      "2023-11-18 11:36:23 (167 MB/s) - ‘data/10k/uber_2021.pdf’ saved [1880483/1880483]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/10k/'\n",
    "!wget 'https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/examples/data/10k/uber_2021.pdf' -O 'data/10k/uber_2021.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0255d1-c3ed-4380-b158-9454161c390c",
   "metadata": {},
   "source": [
    "# 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb0cd13-fd7f-400a-b589-8e2f4e6eb1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "reader = SimpleDirectoryReader(\"./data/10k/\")\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a54123-c46e-438a-b1c7-8267c2410a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ce6fc-07f3-4630-b684-4250a08aea21",
   "metadata": {},
   "source": [
    "# 4. Question Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f7f470-6022-4527-8ee8-7ac65319fe1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-east-1\n",
      "  Using profile: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n",
      "\n",
      "== FM lists ==\n",
      "{'Claude-Instant-V1': 'anthropic.claude-instant-v1',\n",
      " 'Claude-V1': 'anthropic.claude-v1',\n",
      " 'Claude-V2': 'anthropic.claude-v2',\n",
      " 'Command': 'cohere.command-text-v14',\n",
      " 'Jurassic-2-Mid': 'ai21.j2-mid-v1',\n",
      " 'Jurassic-2-Ultra': 'ai21.j2-ultra-v1',\n",
      " 'Llama2-13b-Chat': 'meta.llama2-13b-chat-v1',\n",
      " 'Titan-Embeddings-G1': 'amazon.titan-embed-text-v1',\n",
      " 'Titan-Text-G1': 'TBD'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock, print_ww\n",
    "from utils.bedrock import bedrock_info\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "# os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "print(colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint(bedrock_info.get_list_fm_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aa90f9e-34ee-4f77-9778-259b59f3978a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bedrock(client=<botocore.client.BedrockRuntime object at 0x7f86e7fcf2e0>, model_id='anthropic.claude-v2', model_kwargs={'max_tokens_to_sample': 1024}, streaming=True, callbacks=[<langchain.callbacks.streaming_stdout.StreamingStdOutCallbackHandler object at 0x7f86e7baff40>])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm_claude_v2 = Bedrock(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Claude-V2\"),\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs={\n",
    "        \"max_tokens_to_sample\": 1024\n",
    "    },\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "llm_claude_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c0d4ac-62e1-46f6-bc88-6159139c3c28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm_llama2_chat = Bedrock(\n",
    "#     model_id=bedrock_info.get_model_id(model_name=\"Llama2-13b-Chat\"),\n",
    "#     client=boto3_bedrock,\n",
    "#     model_kwargs={\n",
    "#         \"max_tokens_to_sample\": 1024\n",
    "#     },\n",
    "#     streaming=True,\n",
    "#     callbacks=[StreamingStdOutCallbackHandler()]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12ce5fe4-1fcb-4884-bf31-aff35f77a180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings import LangchainEmbedding\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "\n",
    "# create embeddings\n",
    "bedrock_embedding = BedrockEmbeddings(\n",
    "    client=boto3_bedrock,\n",
    "    model_id=\"amazon.titan-embed-text-v1\",\n",
    ")\n",
    "\n",
    "# load in Bedrock embedding model from langchain\n",
    "embed_model = LangchainEmbedding(bedrock_embedding)\n",
    "\n",
    "#####################################################################\n",
    "# Service Context\n",
    "#####################################################################\n",
    "\n",
    "from llama_index import ServiceContext, set_global_service_context\n",
    "\n",
    "service_context_claude_v2 = ServiceContext.from_defaults(\n",
    "  llm=llm_claude_v2,\n",
    "  embed_model=embed_model,\n",
    "  system_prompt=\"You are an AI assistant answering questions.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3881f4d1-16ee-446a-82c0-0dd7d5c0fe6c",
   "metadata": {},
   "source": [
    "## 1 페이지에 대해서 질문 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5ac623c-16b7-4c9c-a1c2-e941ae68b978",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are 10 potential quiz questions based on the context information provided:\n",
      "\n",
      "1. What is the name of the company filing this 10-K report?\n",
      "\n",
      "2. What is the Commission File Number listed for this company?\n",
      "\n",
      "3. In what state is this company incorporated? \n",
      "\n",
      "4. What is the company's I.R.S. Employer Identification Number?\n",
      "\n",
      "5. What is the company's trading symbol listed on the New York Stock Exchange?\n",
      "\n",
      "6. What form is this company filing with the SEC? \n",
      "\n",
      "7. What act requires the filing of this form?\n",
      "\n",
      "8. Is this company considered a \"well-known seasoned issuer\" according to the context provided?\n",
      "\n",
      "9. What is the address listed for this company's principal executive offices?\n",
      "\n",
      "10. Is this company required to file reports pursuant to Section 13 or Section 15(d) of the Act according to the context?"
     ]
    }
   ],
   "source": [
    "# To evaluate for each chunk size, we will first generate a set of 40 questions from first 20 pages.\n",
    "eval_documents = documents[:1]\n",
    "data_generator = DatasetGenerator.from_documents(eval_documents, service_context=service_context_claude_v2)\n",
    "eval_questions = data_generator.generate_questions_from_nodes(num = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e337a361-eb31-4184-9236-48e552856113",
   "metadata": {},
   "source": [
    "# 5. Setting Up Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0381c643-edd8-4101-ae92-de920434f199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Faithfulness and Relevancy Evaluators which are based on GPT-4\n",
    "faithfulness_claude_v2 = FaithfulnessEvaluator(service_context=service_context_claude_v2)\n",
    "relevancy_claude_v2 = RelevancyEvaluator(service_context=service_context_claude_v2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d9893e-ed42-4e90-a212-a7ee61d25d19",
   "metadata": {},
   "source": [
    "# 6.Response Evaluation For A Chunk Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59aad7f7-138a-48cf-a9e4-7f42815396ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define function to calculate average response time, average faithfulness and average relevancy metrics for given chunk size\n",
    "# We use GPT-3.5-Turbo to generate response and GPT-4 to evaluate it.\n",
    "def evaluate_response_time_and_accuracy(service_context, chunk_size, eval_questions):\n",
    "    \"\"\"\n",
    "    Evaluate the average response time, faithfulness, and relevancy of responses generated by GPT-3.5-turbo for a given chunk size.\n",
    "\n",
    "    Parameters:\n",
    "    chunk_size (int): The size of data chunks being processed.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the average response time, faithfulness, and relevancy metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    total_response_time = 0\n",
    "    total_faithfulness = 0\n",
    "    total_relevancy = 0\n",
    "\n",
    "    # create vector index\n",
    "    # llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "    # service_context = ServiceContext.from_defaults(llm=llm, chunk_size=chunk_size)\n",
    "    vector_index = VectorStoreIndex.from_documents(\n",
    "        eval_documents, service_context=service_context\n",
    "    )\n",
    "    # build query engine\n",
    "    # By default, similarity_top_k is set to 2. To experiment with different values, pass it as an argument to as_query_engine()\n",
    "    query_engine = vector_index.as_query_engine()\n",
    "    num_questions = len(eval_questions)\n",
    "\n",
    "    # Iterate over each question in eval_questions to compute metrics.\n",
    "    # While BatchEvalRunner can be used for faster evaluations (see: https://docs.llamaindex.ai/en/latest/examples/evaluation/batch_eval.html),\n",
    "    # we're using a loop here to specifically measure response time for different chunk sizes.\n",
    "    for question in eval_questions:\n",
    "        print(\"question: \", question)\n",
    "        start_time = time.time()\n",
    "        response_vector = query_engine.query(question)\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        faithfulness_result = faithfulness_claude_v2.evaluate_response(\n",
    "            response=response_vector\n",
    "        ).passing\n",
    "\n",
    "        relevancy_result = relevancy_claude_v2.evaluate_response(\n",
    "            query=question, response=response_vector\n",
    "        ).passing\n",
    "\n",
    "        \n",
    "        total_response_time += elapsed_time\n",
    "        total_faithfulness += faithfulness_result\n",
    "        total_relevancy += relevancy_result\n",
    "\n",
    "    average_response_time = total_response_time / num_questions\n",
    "    average_faithfulness = total_faithfulness / num_questions\n",
    "    average_relevancy = total_relevancy / num_questions\n",
    "\n",
    "    return average_response_time, average_faithfulness, average_relevancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26d97812-d016-43f9-b405-f156f35ce57e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  Here are 10 potential quiz questions based on the context information provided:\n",
      " Here are 10 potential quiz questions based on the context:\n",
      "\n",
      "1. What is the full name of the company filing this Annual Report?\n",
      "\n",
      "2. What is the fiscal year end date for this Annual Report? \n",
      "\n",
      "3. What city and state is Uber Technologies, Inc. headquartered in?\n",
      "\n",
      "4. What stock exchange does Uber trade its common stock on?\n",
      "\n",
      "5. What is Uber's SEC file number?\n",
      "\n",
      "6. What form type is this filing? \n",
      "\n",
      "7. What is Uber's IRS Employer Identification Number?\n",
      "\n",
      "8. Is Uber required to file reports under Section 13 or 15(d) of the Securities Exchange Act?\n",
      "\n",
      "9. Has Uber filed all reports required under Section 13 or 15(d) of the Securities Exchange Act over the past 12 months?\n",
      "\n",
      "10. What is Uber's trading symbol on the stock exchange? Here are the answers to the 10 potential quiz questions:\n",
      "\n",
      "1. YES - Uber Technologies, Inc.\n",
      "2. YES - December 31, 2021\n",
      "3. YES - San Francisco, California  \n",
      "4. YES - New York Stock Exchange\n",
      "5. YES - 001-38902\n",
      "6. YES - Form 10-K \n",
      "7. YES - 45-2647441\n",
      "8. YES - Yes\n",
      "9. YES - Yes\n",
      "10. YES - UBER Yes, the response is in line with the context. The response provides 10 potential quiz questions that are based on details and information contained in the context, which is an annual report form filing for Uber Technologies, Inc. The questions cover key details like the company name, fiscal year, headquarters location, stock exchange, SEC file number, filing type, IRS number, reporting requirements, trading symbol, etc. So the quiz questions accurately reflect and are in line with the context provided.question:  What is the name of the company filing this 10-K report?\n",
      " Based on the context, the name of the company filing this 10-K report is Uber Technologies, Inc. The first line of the document states this is a Form 10-K for Uber Technologies, Inc. YES\n",
      "\n",
      "The first line of the context states this is a Form 10-K for Uber Technologies, Inc. Therefore, the information that the name of the company filing this 10-K report is Uber Technologies, Inc. is supported by the context. YESquestion:  What is the Commission File Number listed for this company?\n",
      " Based on the context given, the Commission File Number listed for this company is 001-38902. This is specified on page 1 in the line that says \"Commission File Number: 001-38902\". YES\n",
      "\n",
      "The context contains the line \"Commission File Number: 001-38902\" on page 1, which supports the information that the Commission File Number for this company is 001-38902. Yes, the response is in line with the context information provided. The context mentions that the Commission File Number for the company is 001-38902, which is specified on page 1. The response correctly states that the Commission File Number listed for this company is 001-38902, confirming it is in line with the context.question:  In what state is this company incorporated?\n",
      " Based on the context, Uber Technologies, Inc. is incorporated in Delaware. The Form 10-K states:\n",
      "\n",
      "\"UBER TECHNOLOGIES, INC.(Exact name of registrant as specified in its charter)Delaware45-2647441(State or other jurisdiction of incorporation or organization)(I.R.S. Employer Identification No.)\"\n",
      "\n",
      "So Uber Technologies, Inc. is incorporated in the state of Delaware. YES\n",
      "\n",
      "The context states:\n",
      "\n",
      "\"UBER TECHNOLOGIES, INC.(Exact name of registrant as specified in its charter)Delaware45-2647441(State or other jurisdiction of incorporation or organization)(I.R.S. Employer Identification No.)\"\n",
      "\n",
      "This directly supports the information that Uber Technologies, Inc. is incorporated in Delaware. Yes, the response is in line with the context information. The context contains an excerpt from Uber's Form 10-K annual report filed with the SEC. The response cites the relevant section from the Form 10-K that states Uber Technologies, Inc. is incorporated in Delaware. Since the response directly references and quotes the provided context, it is consistent.question:  What is the company's I.R.S. Employer Identification Number?\n",
      " Based on the context, the company's I.R.S. Employer Identification Number is 45-2647441. This is indicated in the passage:\n",
      "\n",
      "\"(Exact name of registrant as specified in its charter)\n",
      "Delaware \n",
      "45-2647441 (State or other jurisdiction of incorporation or organization)(I.R.S. Employer Identification No.)\" YES\n",
      "\n",
      "The given information states that the company's I.R.S. Employer Identification Number is 45-2647441. This is supported by the context, which contains the line \"(I.R.S. Employer Identification No.) 45-2647441\". Therefore, the answer is YES. YES\n",
      "\n",
      "The response is in line with the context information. The context indicates that the company's I.R.S. Employer Identification Number is 45-2647441, which matches the response.question:  What is the company's trading symbol listed on the New York Stock Exchange?\n",
      " Based on the context, Uber Technologies, Inc.'s trading symbol listed on the New York Stock Exchange is UBER.\n",
      "\n",
      "The relevant context is:\n",
      "\"Securities registered pursuant to Section 12(b) of the Act:\n",
      "Title of each class Trading Symbol(s) Name of each exchange on which registered \n",
      "Common Stock, par value $0.00001 per share UBER New York Stock Exchange\"\n",
      "\n",
      "This indicates that Uber Technologies, Inc.'s common stock trades under the symbol UBER on the New York Stock Exchange. YES\n",
      "\n",
      "The given information is:\n",
      "\n",
      "Based on the context, Uber Technologies, Inc.'s trading symbol listed on the New York Stock Exchange is UBER.\n",
      "\n",
      "The relevant context is:\n",
      "\n",
      "\"Securities registered pursuant to Section 12(b) of the Act: \n",
      "Title of each class Trading Symbol(s) Name of each exchange on which registered  \n",
      "Common Stock, par value $0.00001 per share UBER New York Stock Exchange\"\n",
      "\n",
      "This directly states that Uber Technologies, Inc.'s common stock trades under the symbol UBER on the New York Stock Exchange. Therefore, the given information is supported by the context, so the answer is YES. YES, the response is in line with the context provided. The context indicates that Uber Technologies, Inc.'s common stock trades under the symbol UBER on the New York Stock Exchange. The response states that based on this context, Uber Technologies, Inc.'s trading symbol listed on the NYSE is UBER, which is consistent.question:  What form is this company filing with the SEC?\n",
      " Based on the context, this company is filing an Annual Report Pursuant to Section 13 or 15(d) of the Securities Exchange Act of 1934 (Form 10-K) with the SEC.\n",
      "\n",
      "The first line indicates this is a Form 10-K. Further down, it states \"ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934For the fiscal year ended\n",
      " December 31, 2021\". This confirms it is an annual report Form 10-K being filed with the SEC. YES\n",
      "\n",
      "The context supports the information that this is an Annual Report Form 10-K being filed with the SEC. The first line indicates it is a Form 10-K. Further down, it explicitly states \"ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934For the fiscal year ended December 31, 2021\". This confirms it is an annual report Form 10-K being filed with the SEC. YES. The response is in line with the context. The context indicates this is an Annual Report (Form 10-K) being filed with the SEC for the fiscal year ended December 31, 2021. The response states that based on the context, this is a Form 10-K Annual Report being filed with the SEC, which matches the details provided in the context.question:  What act requires the filing of this form?\n",
      " Based on the context, this Form 10-K is being filed pursuant to Section 13 or 15(d) of the Securities Exchange Act of 1934, as stated in the first paragraph. The Securities Exchange Act of 1934 requires the filing of this form. YES\n",
      "\n",
      "The given information is:\n",
      "\"Based on the context, this Form 10-K is being filed pursuant to Section 13 or 15(d) of the Securities Exchange Act of 1934, as stated in the first paragraph. The Securities Exchange Act of 1934 requires the filing of this form.\"\n",
      "\n",
      "The first paragraph of the context states:\n",
      "\"FORM 10-K (Mark One) ☒ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\"\n",
      "\n",
      "This supports the information that the Form 10-K is being filed pursuant to Section 13 or 15(d) of the Securities Exchange Act of 1934. Therefore, the answer is YES. YES\n",
      "\n",
      "The response is in line with the context. The context indicates this is a Form 10-K being filed under the Securities Exchange Act of 1934. The response correctly states that the Securities Exchange Act of 1934 requires the filing of this form, answering the question of what act requires the filing of the form. Therefore, the response is consistent with the information provided in the context.question:  Is this company considered a \"well-known seasoned issuer\" according to the context provided?\n",
      " Based on the context, Uber Technologies Inc. would be considered a well-known seasoned issuer. The Form 10-K indicates that the company checked \"Yes\" in response to the question \"Indicate by check mark whether the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act.\" This directly states that Uber Technologies Inc. is considered a well-known seasoned issuer. YES\n",
      "\n",
      "The context indicates that in its Form 10-K filing, Uber Technologies Inc. checked \"Yes\" in response to the question \"Indicate by check mark whether the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act.\" This directly supports the information that Uber Technologies Inc. would be considered a well-known seasoned issuer. Yes, the response is in line with the context information. The context indicates that Uber Technologies Inc. checked \"Yes\" in response to being a well-known seasoned issuer on the Form 10-K. The response states that based on this, Uber Technologies Inc. would be considered a well-known seasoned issuer, which is consistent.question:  What is the address listed for this company's principal executive offices?\n",
      " Based on the context information provided, the address listed for this company's principal executive offices is:\n",
      "\n",
      "1515 3rd Street \n",
      "San Francisco, California 94158\n",
      "\n",
      "This is stated in the paragraph that begins \"(Address of principal executive offic...\". YES\n",
      "\n",
      "The given information matches the address stated in the specified paragraph of the context. The context states \"1515 3rd Street, San Francisco, California 94158\" as the address of the company's principal executive offices, which matches the address provided in the information. YES, the response for the query is in line with the context information provided. The context paragraph states that the company's principal executive offices are located at \"1515 3rd Street, San Francisco, California 94158\", which matches the address provided in the response.question:  Is this company required to file reports pursuant to Section 13 or Section 15(d) of the Act according to the context?\n",
      " Based on the context provided, specifically the statement \"Indicate by check mark whether the registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the Act. Yes ☐ No ☒\", the company Uber Technologies, Inc. is required to file reports pursuant to Section 13 or Section 15(d) of the Act. The \"No\" is checked indicating they are required to file reports under those sections. YES\n",
      "\n",
      "The context indicates that Uber Technologies, Inc. is required to file reports pursuant to Section 13 or Section 15(d) of the Act, as the \"No\" box is checked next to the statement \"Indicate by check mark whether the registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the Act.\" This supports the information that Uber Technologies, Inc. is required to file these reports. Yes, the response is in line with the context information provided. The context indicates that Uber Technologies, Inc. is required to file reports under Section 13 or Section 15(d) of the Act by checking \"No\" next to the statement \"Indicate by check mark whether the registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the Act.\" Since the \"No\" box is checked, it means the company is required to file reports under those sections. The response accurately states this based on the context.Chunk size 256 - Average Response time: 4.33s, Average Faithfulness: 1.00, Average Relevancy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Iterate over different chunk sizes to evaluate the metrics to help fix the chunk size.\n",
    "\n",
    "# for chunk_size in [128, 256, 512, 1024, 2048]:\n",
    "for chunk_size in [256]:\n",
    "  avg_response_time, avg_faithfulness, avg_relevancy = evaluate_response_time_and_accuracy(service_context_claude_v2,\n",
    "                                                                                           chunk_size, \n",
    "                                                                                           eval_questions)\n",
    "  print(f\"Chunk size {chunk_size} - Average Response time: {avg_response_time:.2f}s, Average Faithfulness: {avg_faithfulness:.2f}, Average Relevancy: {avg_relevancy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c223ca7-e85d-451c-8c49-d796755da8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
